{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fusion transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1uNh0HydMlsFywzjMOpvfbUC3Ph2QKmjC",
      "authorship_tag": "ABX9TyMLUMii8nHZJw6ZQQYNxV8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumedh151/fusion-transformer/blob/main/fusion_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G2CekCSGcsD",
        "outputId": "8800f821-13bf-454d-e77e-b298d7f3820d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 348 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.6)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2022.6.15)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.10 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio\n",
        "import rasterio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tqdm\n",
        "import gc\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "g8RlbPvHsSoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/__MACOSX\n",
        "!rm -rf /content/2013_DFTC"
      ],
      "metadata": {
        "id": "Huc640OvJTgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/datasets/houston/2013_DFTC.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm2MpNxHGstM",
        "outputId": "0f3a6501-dde0-4630-ca13-4309849819c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/datasets/houston/2013_DFTC.zip\n",
            "   creating: 2013_DFTC/\n",
            "  inflating: 2013_DFTC/2013_IEEE_GRSS_DF_Contest_CASI.hdr  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/2013_DFTC/\n",
            "  inflating: __MACOSX/2013_DFTC/._2013_IEEE_GRSS_DF_Contest_CASI.hdr  \n",
            "  inflating: 2013_DFTC/2013_IEEE_GRSS_DF_Contest_CASI.tif  \n",
            "  inflating: __MACOSX/2013_DFTC/._2013_IEEE_GRSS_DF_Contest_CASI.tif  \n",
            "  inflating: 2013_DFTC/2013_IEEE_GRSS_DF_Contest_LiDAR.hdr  \n",
            "  inflating: __MACOSX/2013_DFTC/._2013_IEEE_GRSS_DF_Contest_LiDAR.hdr  \n",
            "  inflating: 2013_DFTC/2013_IEEE_GRSS_DF_Contest_LiDAR.tif  \n",
            "  inflating: __MACOSX/2013_DFTC/._2013_IEEE_GRSS_DF_Contest_LiDAR.tif  \n",
            "  inflating: 2013_DFTC/2013_IEEE_GRSS_DF_Contest_Samples_TR.roi  \n",
            "  inflating: __MACOSX/2013_DFTC/._2013_IEEE_GRSS_DF_Contest_Samples_TR.roi  \n",
            "  inflating: 2013_DFTC/2013_IEEE_GRSS_DF_Contest_Samples_TR.txt  \n",
            "  inflating: __MACOSX/2013_DFTC/._2013_IEEE_GRSS_DF_Contest_Samples_TR.txt  \n",
            "  inflating: 2013_DFTC/2013_IEEE_GRSS_DF_Contest_Samples_VA.zip  \n",
            "  inflating: __MACOSX/2013_DFTC/._2013_IEEE_GRSS_DF_Contest_Samples_VA.zip  \n",
            "  inflating: 2013_DFTC/copyright.txt  \n",
            "  inflating: __MACOSX/2013_DFTC/._copyright.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/__MACOSX"
      ],
      "metadata": {
        "id": "f5S_fX_GJhZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = rasterio.open('/content/2013_DFTC/2013_IEEE_GRSS_DF_Contest_CASI.tif')"
      ],
      "metadata": {
        "id": "k0Vr4JeVJFGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced0c237-7a4f-4584-b187-1895eb5d5879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rasterio._env:CPLE_AppDefined in /content/2013_DFTC/2013_IEEE_GRSS_DF_Contest_CASI.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn5EvfhkJI5G",
        "outputId": "d20d2457-da24-4744-b20b-db9865f55e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(349, 1905)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.read(1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ASv0RQJrZ_",
        "outputId": "1226c1c1-1892-4c7b-e830-fea5384aec5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(349, 1905)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "hysp=np.zeros((144,349,1905))\n",
        "for i in range(144):\n",
        "  x=ds.read(i+1)\n",
        "  m=np.amax(x)\n",
        "  x=x/m\n",
        "  hysp[i]=x\n",
        "print(hysp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD2ef3zgJKX5",
        "outputId": "b20c9840-733e-4ec1-dc17-be2d96205f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(144, 349, 1905)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hysp1=np.swapaxes(hysp,2,0)"
      ],
      "metadata": {
        "id": "J-WZDR-YJLzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "a=hysp1[:,:,50]\n",
        "print(a.shape)\n",
        "# plt.plot(hysp[:,:,1])\n",
        "plt.imshow(a.T,cmap=\"jet\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "5aAEyJqIJOXV",
        "outputId": "a1b14cd9-9478-4b8d-92c7-ea4941177a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1905, 349)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df =pd.read_csv(\"/content/drive/MyDrive/datasets/houston/trainingdata.txt\",delimiter=\"\\t\")\n",
        "df.rename(columns={\"769\":\"x\",\"7\":\"y\",\"1\":\"category\"},inplace=True)\n",
        "left=pd.DataFrame({\"x\":\"769\",\"y\":\"7\",\"category\":\"1\"},index =[0])\n",
        "df = pd.concat([left, df]).reset_index(drop = True)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkrGoYBzJQqE",
        "outputId": "e8363805-328e-45dd-92ac-4bfe3bee932f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        x    y category\n",
            "0     769    7        1\n",
            "1     768    7        1\n",
            "2     772    7        1\n",
            "3     771    7        1\n",
            "4     770    7        1\n",
            "...   ...  ...      ...\n",
            "2827  293  172       15\n",
            "2828  293  173       15\n",
            "2829  294  173       15\n",
            "2830  292  173       15\n",
            "2831  293  174       15\n",
            "\n",
            "[2832 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.to_numpy()\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anYMb4sgPj9q",
        "outputId": "4756d2f6-20d3-4e87-e076-451c1af4de44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['769' '7' '1']\n",
            " [768 7 1]\n",
            " [772 7 1]\n",
            " ...\n",
            " [294 173 15]\n",
            " [292 173 15]\n",
            " [293 174 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bj4zLPcPuy9",
        "outputId": "92a7bc67-0d0c-41e4-f59b-32d496bc274b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2832, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_label_tr=np.zeros(2832)\n",
        "\n",
        "for i in range(2832):\n",
        "  y_label_tr[i]=df[i][2]"
      ],
      "metadata": {
        "id": "XGyt-YXSPq7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_label_tr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drc8P6eRPs31",
        "outputId": "85f083b7-015e-4e87-df1f-3131a3ef658f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2832,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds2=rasterio.open(\"/content/2013_DFTC/2013_IEEE_GRSS_DF_Contest_LiDAR.tif\")\n",
        "print(ds2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhkjwajOPxjd",
        "outputId": "445bcbe3-b78e-4c13-fc2e-60cb5a084e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(349, 1905)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=ds2.read(1)\n",
        "m=np.amax(x)\n",
        "x=x/m\n",
        "ll=np.swapaxes(x,0,1)\n",
        "print(ll.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJSt82UYQDmz",
        "outputId": "79586a2f-3559-471e-fc5d-d91c0e485d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1905, 349)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_co = np.genfromtxt('/content/drive/MyDrive/datasets/houston/test.txt')\n",
        "test_co.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuCUInSnQFQv",
        "outputId": "350a4b4a-5be9-45bb-80e9-91260bcab8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12197, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_co = np.genfromtxt('/content/drive/MyDrive/datasets/houston/trainingdata.txt')\n",
        "train_co.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82Pb95HhQHx2",
        "outputId": "6c1cda6d-b991-46c1-fd84-386d6962325a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2832, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p=11\n",
        "hs_tr=np.zeros((2832,p,p,144))\n",
        "ld_tr=np.zeros((2832,p,p))\n",
        "train_label=np.zeros(2832)\n",
        "for i in range(2832):\n",
        "  x=int(train_co[i][0])\n",
        "  y=int(train_co[i][1])\n",
        "  train_label[i]=int(train_co[i][2]-1)\n",
        "  if y>=6 and y<=344 and x>=6 and x<=1898:\n",
        "      hs_tr[i]=hysp1[ x-6:x+5 , y-6:y+5 ,:]\n",
        "      ld_tr[i]=ll[ x-6:x+5 , y-6:y+5 ]\n",
        "  \n",
        "print(hs_tr.shape)\n",
        "\n",
        "ld_tr=np.reshape(ld_tr,(2832,11,11,1))\n",
        "print(ld_tr.shape)\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBiTew78QKZ1",
        "outputId": "53b39e9e-aee8-4c9c-9f68-4eea3ad4dc8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2832, 11, 11, 144)\n",
            "(2832, 11, 11, 1)\n",
            "(2832,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p=11\n",
        "hs_tt=np.zeros((12197,p,p,144))\n",
        "ld_tt=np.zeros((12197,p,p))\n",
        "test_label=np.zeros(12197)\n",
        "for i in range(12197):\n",
        "  x=int(test_co[i][0])\n",
        "  y=int(test_co[i][1])\n",
        "  test_label[i]=int(test_co[i][2]-1)\n",
        "  if y>=6 and y<=344 and x>=6 and x<=1898:\n",
        "      hs_tt[i]=hysp1[ x-6:x+5 , y-6:y+5 ,:]\n",
        "      ld_tt[i]=ll[ x-6:x+5 , y-6:y+5 ]\n",
        "  \n",
        "print(hs_tt.shape)\n",
        "\n",
        "ld_tt=np.reshape(ld_tt,(12197,11,11,1))\n",
        "print(ld_tt.shape)\n",
        "print(test_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK2RnEqjQNbT",
        "outputId": "bc15e16a-be67-4773-933d-ca3e523fbae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12197, 11, 11, 144)\n",
            "(12197, 11, 11, 1)\n",
            "(12197,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        # print(\"batch_size\",batch_size)\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        # print(\"patches shape\",patches.shape)\n",
        "        return patches"
      ],
      "metadata": {
        "id": "r9-L27QX1rQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "naXdavCpoTCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim      \n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, hs_input, ld_input, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=hs_input, value=ld_input, key=hs_input\n",
        "        )\n",
        "        # print(\"attention_output\",attention_output)\n",
        "        proj_input = self.layernorm_1(hs_input + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)"
      ],
      "metadata": {
        "id": "SteV4Wo05p9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 11\n",
        "patch_size = 1 \n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 256\n",
        "embed_dim = 256\n",
        "dense_dim = 1024\n",
        "num_heads = 8\n",
        "\n",
        "hs_inp = keras.Input(shape=(image_size,image_size,144))\n",
        "ld_inp = keras.Input(shape=(image_size,image_size,1))\n",
        "\n",
        "hs_patches = Patches(patch_size=patch_size)(hs_inp)\n",
        "ld_patches = Patches(patch_size=patch_size)(ld_inp)\n",
        "\n",
        "hs_encoded_patches = PatchEncoder(num_patches, projection_dim)(hs_patches)\n",
        "ld_encoded_patches = PatchEncoder(num_patches, projection_dim)(ld_patches)\n",
        "\n",
        "encoder = TransformerEncoder(embed_dim, dense_dim, num_heads)(hs_encoded_patches, ld_encoded_patches)\n",
        "encoder_1 = TransformerEncoder(embed_dim, dense_dim, num_heads)(encoder, ld_encoded_patches)\n",
        "encoder_2 = TransformerEncoder(embed_dim, dense_dim, num_heads)(encoder, hs_encoded_patches)\n",
        "add = layers.Add()([encoder_1, encoder_2])\n",
        "\n",
        "flatten = layers.Flatten()(add)\n",
        "output = layers.Dense(15, activation=\"softmax\")(flatten)\n",
        "model = keras.Model((hs_inp,ld_inp), output)"
      ],
      "metadata": {
        "id": "VlSzxiM0hKTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfi7GKzR21lu",
        "outputId": "6f313ee2-7245-4daf-dec9-5cf95facda74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 11, 11, 144  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 11, 11, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " patches_2 (Patches)            (None, None, 144)    0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " patches_3 (Patches)            (None, None, 1)      0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " patch_encoder_2 (PatchEncoder)  (None, 121, 256)    68096       ['patches_2[0][0]']              \n",
            "                                                                                                  \n",
            " patch_encoder_3 (PatchEncoder)  (None, 121, 256)    31488       ['patches_3[0][0]']              \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Transfo  (None, 121, 256)    2630144     ['patch_encoder_2[0][0]',        \n",
            " rmerEncoder)                                                     'patch_encoder_3[0][0]']        \n",
            "                                                                                                  \n",
            " transformer_encoder_2 (Transfo  (None, 121, 256)    2630144     ['transformer_encoder_1[0][0]',  \n",
            " rmerEncoder)                                                     'patch_encoder_3[0][0]']        \n",
            "                                                                                                  \n",
            " transformer_encoder_3 (Transfo  (None, 121, 256)    2630144     ['transformer_encoder_1[0][0]',  \n",
            " rmerEncoder)                                                     'patch_encoder_2[0][0]']        \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 121, 256)     0           ['transformer_encoder_2[0][0]',  \n",
            "                                                                  'transformer_encoder_3[0][0]']  \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 30976)        0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 15)           464655      ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,454,671\n",
            "Trainable params: 8,454,671\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hs_tr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CazO-dDhGY8o",
        "outputId": "eb282e59-5182-49b3-c07e-0213098de5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2832, 11, 11, 144)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ld_tr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAJB8FNYHOcy",
        "outputId": "b0c24988-72a6-4d49-a939-39e408e330b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2832, 11, 11, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_label.shape)\n",
        "print(max(train_label))\n",
        "print(min(train_label))"
      ],
      "metadata": {
        "id": "-KvJomsJyWdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c376a6d-9411-4b4d-f674-f19f51db8621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2832,)\n",
            "14.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hs_tr90 = np.empty([2832,11,11,144], dtype = 'float32')\n",
        "hs_tr180 = np.empty([2832,11,11,144], dtype = 'float32')\n",
        "hs_tr270 = np.empty([2832,11,11,144], dtype = 'float32')\n",
        "\n",
        "ld_tr90 = np.empty([2832,11,11,1], dtype = 'float32')\n",
        "ld_tr180 = np.empty([2832,11,11,1], dtype = 'float32')\n",
        "ld_tr270 = np.empty([2832,11,11,1], dtype = 'float32')\n",
        "\n",
        "for i in tqdm.tqdm(range(2832)):\n",
        "  hs_tr90[i,:,:,:] = np.rot90(hs_tr[i,:,:,:])\n",
        "  hs_tr180[i,:,:,:] = np.rot90(hs_tr90[i,:,:,:])\n",
        "  hs_tr270[i,:,:,:] = np.rot90(hs_tr180[i,:,:,:])\n",
        "\n",
        "  ld_tr90[i,:,:,:] = np.rot90(ld_tr[i,:,:,:])\n",
        "  ld_tr180[i,:,:,:] = np.rot90(ld_tr90[i,:,:,:])\n",
        "  ld_tr270[i,:,:,:] = np.rot90(ld_tr180[i,:,:,:])  \n",
        "\n",
        "hs_train_patches = np.concatenate([hs_tr, hs_tr90, hs_tr180, hs_tr270], axis = 0)\n",
        "ld_train_patches = np.concatenate([ld_tr, ld_tr90, ld_tr180, ld_tr270], axis = 0)\n",
        "train_labels = np.concatenate([train_label, train_label, train_label, train_label] , axis = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyDHdwpSG5ls",
        "outputId": "2a8c2255-d9af-41a5-88d3-07e1a780daef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2832/2832 [00:00<00:00, 8947.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hs_train_patches.shape)\n",
        "print(ld_train_patches.shape)\n",
        "print(train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFeoiMoFHwKm",
        "outputId": "6de19945-800f-4505-ed4b-f8f700e63c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11328, 11, 11, 144)\n",
            "(11328, 11, 11, 1)\n",
            "(11328,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=15, dtype=\"float32\")"
      ],
      "metadata": {
        "id": "JSTh3rPUF0tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_test_labels = tf.keras.utils.to_categorical(test_label, num_classes=15, dtype=\"float32\")"
      ],
      "metadata": {
        "id": "9lUIvxkCJr_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(categorical_train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pjSrVkkH5j2",
        "outputId": "0476c334-a313-4fc2-a4a2-30a77aaec615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11328, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(categorical_test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ydAD7SJ0Kz",
        "outputId": "af9af635-2e14-4529-cbff-595fc5eca974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12197, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_KYKYlNeH7wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss= 'categorical_crossentropy' , optimizer= tf.keras.optimizers.Adam(learning_rate=5e-6) , metrics=[ 'accuracy' ])"
      ],
      "metadata": {
        "id": "88tnPj0yIo3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochaccuracy = []\n",
        "highestaccuracy = [0]\n",
        "trainacc = []"
      ],
      "metadata": {
        "id": "HG68HUzJIpaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_acc = highestaccuracy[-1]\n",
        "ep = 0\n",
        "predsf = np.zeros((12917, 15))\n",
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "  gc.collect()\n",
        "  history = model.fit((hs_train_patches, ld_train_patches), categorical_train_labels, batch_size = 32, epochs=1)\n",
        "  trainacc.append(history.history[\"accuracy\"])\n",
        "  preds = model.predict((hs_tt, ld_tt))\n",
        "  conf = confusion_matrix(test_label, np.argmax(preds,1)) \n",
        "  acc = np.trace(conf)/np.sum(conf)\n",
        "  if acc>temp_acc:\n",
        "    temp_acc = acc\n",
        "    ep = i\n",
        "    predsf = preds\n",
        "  print('acc_max = ', np.round(100*temp_acc,2), '% at epoch', ep)\n",
        "  highestaccuracy.append(temp_acc)\n",
        "  print('epoch_acc = ', round(100*acc,2), '% at epoch', i)\n",
        "  epochaccuracy.append(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u6I0pjtbJARK",
        "outputId": "7b23160a-0efe-4601-d495-5a2ddaffa24e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354/354 [==============================] - 24s 63ms/step - loss: 1.5450 - accuracy: 0.5439\n",
            "acc_max =  61.75 % at epoch 0\n",
            "epoch_acc =  61.75 % at epoch 0\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.7330 - accuracy: 0.7951\n",
            "acc_max =  64.46 % at epoch 1\n",
            "epoch_acc =  64.46 % at epoch 1\n",
            "354/354 [==============================] - 22s 61ms/step - loss: 0.5079 - accuracy: 0.8445\n",
            "acc_max =  65.92 % at epoch 2\n",
            "epoch_acc =  65.92 % at epoch 2\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.3928 - accuracy: 0.8762\n",
            "acc_max =  70.41 % at epoch 3\n",
            "epoch_acc =  70.41 % at epoch 3\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.3101 - accuracy: 0.9022\n",
            "acc_max =  71.46 % at epoch 4\n",
            "epoch_acc =  71.46 % at epoch 4\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 0.2320 - accuracy: 0.9327\n",
            "acc_max =  75.13 % at epoch 5\n",
            "epoch_acc =  75.13 % at epoch 5\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.1795 - accuracy: 0.9497\n",
            "acc_max =  75.73 % at epoch 6\n",
            "epoch_acc =  75.73 % at epoch 6\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.1479 - accuracy: 0.9612\n",
            "acc_max =  76.51 % at epoch 7\n",
            "epoch_acc =  76.51 % at epoch 7\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.1260 - accuracy: 0.9685\n",
            "acc_max =  77.68 % at epoch 8\n",
            "epoch_acc =  77.68 % at epoch 8\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.1062 - accuracy: 0.9757\n",
            "acc_max =  77.68 % at epoch 8\n",
            "epoch_acc =  77.32 % at epoch 9\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0939 - accuracy: 0.9789\n",
            "acc_max =  78.86 % at epoch 10\n",
            "epoch_acc =  78.86 % at epoch 10\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0807 - accuracy: 0.9838\n",
            "acc_max =  78.86 % at epoch 10\n",
            "epoch_acc =  78.25 % at epoch 11\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0722 - accuracy: 0.9862\n",
            "acc_max =  78.86 % at epoch 10\n",
            "epoch_acc =  78.63 % at epoch 12\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0652 - accuracy: 0.9886\n",
            "acc_max =  78.87 % at epoch 13\n",
            "epoch_acc =  78.87 % at epoch 13\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0580 - accuracy: 0.9891\n",
            "acc_max =  79.27 % at epoch 14\n",
            "epoch_acc =  79.27 % at epoch 14\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0515 - accuracy: 0.9919\n",
            "acc_max =  79.94 % at epoch 15\n",
            "epoch_acc =  79.94 % at epoch 15\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0471 - accuracy: 0.9918\n",
            "acc_max =  79.94 % at epoch 15\n",
            "epoch_acc =  79.09 % at epoch 16\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0412 - accuracy: 0.9945\n",
            "acc_max =  80.51 % at epoch 17\n",
            "epoch_acc =  80.51 % at epoch 17\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0377 - accuracy: 0.9938\n",
            "acc_max =  80.51 % at epoch 17\n",
            "epoch_acc =  79.58 % at epoch 18\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0337 - accuracy: 0.9946\n",
            "acc_max =  80.63 % at epoch 19\n",
            "epoch_acc =  80.63 % at epoch 19\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0300 - accuracy: 0.9952\n",
            "acc_max =  80.63 % at epoch 19\n",
            "epoch_acc =  80.06 % at epoch 20\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0273 - accuracy: 0.9960\n",
            "acc_max =  80.77 % at epoch 21\n",
            "epoch_acc =  80.77 % at epoch 21\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0237 - accuracy: 0.9970\n",
            "acc_max =  80.94 % at epoch 22\n",
            "epoch_acc =  80.94 % at epoch 22\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0217 - accuracy: 0.9971\n",
            "acc_max =  80.94 % at epoch 22\n",
            "epoch_acc =  79.66 % at epoch 23\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0184 - accuracy: 0.9981\n",
            "acc_max =  80.94 % at epoch 22\n",
            "epoch_acc =  80.91 % at epoch 24\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0169 - accuracy: 0.9982\n",
            "acc_max =  81.22 % at epoch 25\n",
            "epoch_acc =  81.22 % at epoch 25\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0192 - accuracy: 0.9963\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.84 % at epoch 26\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0138 - accuracy: 0.9988\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.62 % at epoch 27\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0110 - accuracy: 0.9996\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.28 % at epoch 28\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 0.0104 - accuracy: 0.9990\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.3 % at epoch 29\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0090 - accuracy: 0.9995\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  80.31 % at epoch 30\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0086 - accuracy: 0.9996\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.82 % at epoch 31\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0082 - accuracy: 0.9996\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.28 % at epoch 32\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 0.0066 - accuracy: 0.9996\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.22 % at epoch 33\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.06 % at epoch 34\n",
            "354/354 [==============================] - 22s 61ms/step - loss: 0.0048 - accuracy: 0.9999\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.35 % at epoch 35\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.73 % at epoch 36\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0044 - accuracy: 0.9999\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.13 % at epoch 37\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.66 % at epoch 38\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0063 - accuracy: 0.9989\n",
            "acc_max =  81.84 % at epoch 26\n",
            "epoch_acc =  81.45 % at epoch 39\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.93 % at epoch 40\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0030 - accuracy: 0.9998\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.41 % at epoch 41\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.25 % at epoch 42\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.77 % at epoch 43\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.5 % at epoch 44\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 0.0019 - accuracy: 0.9999\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  80.99 % at epoch 45\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.91 % at epoch 46\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0024 - accuracy: 0.9998\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.66 % at epoch 47\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.57 % at epoch 48\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.5802e-04 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.82 % at epoch 49\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  80.79 % at epoch 50\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.83 % at epoch 51\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.4724e-04 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.68 % at epoch 52\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.3754e-04 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.69 % at epoch 53\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.2168e-04 - accuracy: 1.0000\n",
            "acc_max =  81.93 % at epoch 40\n",
            "epoch_acc =  81.68 % at epoch 54\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.8792e-04 - accuracy: 1.0000\n",
            "acc_max =  82.2 % at epoch 55\n",
            "epoch_acc =  82.2 % at epoch 55\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0057 - accuracy: 0.9979\n",
            "acc_max =  82.2 % at epoch 55\n",
            "epoch_acc =  81.28 % at epoch 56\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.9214e-04 - accuracy: 1.0000\n",
            "acc_max =  82.2 % at epoch 55\n",
            "epoch_acc =  81.68 % at epoch 57\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.1385e-04 - accuracy: 1.0000\n",
            "acc_max =  82.2 % at epoch 55\n",
            "epoch_acc =  81.91 % at epoch 58\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.8573e-04 - accuracy: 1.0000\n",
            "acc_max =  82.21 % at epoch 59\n",
            "epoch_acc =  82.21 % at epoch 59\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.6746e-04 - accuracy: 1.0000\n",
            "acc_max =  82.21 % at epoch 59\n",
            "epoch_acc =  81.91 % at epoch 60\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.5383e-04 - accuracy: 1.0000\n",
            "acc_max =  82.21 % at epoch 59\n",
            "epoch_acc =  81.89 % at epoch 61\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.2800e-04 - accuracy: 1.0000\n",
            "acc_max =  82.31 % at epoch 62\n",
            "epoch_acc =  82.31 % at epoch 62\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.3840e-04 - accuracy: 1.0000\n",
            "acc_max =  82.37 % at epoch 63\n",
            "epoch_acc =  82.37 % at epoch 63\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.0458e-04 - accuracy: 1.0000\n",
            "acc_max =  82.37 % at epoch 63\n",
            "epoch_acc =  81.96 % at epoch 64\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.1702e-04 - accuracy: 1.0000\n",
            "acc_max =  82.45 % at epoch 65\n",
            "epoch_acc =  82.45 % at epoch 65\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.0982e-04 - accuracy: 1.0000\n",
            "acc_max =  82.45 % at epoch 65\n",
            "epoch_acc =  82.06 % at epoch 66\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.6323e-04 - accuracy: 1.0000\n",
            "acc_max =  82.45 % at epoch 65\n",
            "epoch_acc =  81.6 % at epoch 67\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0052 - accuracy: 0.9985\n",
            "acc_max =  82.76 % at epoch 68\n",
            "epoch_acc =  82.76 % at epoch 68\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.6143e-04 - accuracy: 1.0000\n",
            "acc_max =  82.76 % at epoch 68\n",
            "epoch_acc =  82.74 % at epoch 69\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.2941e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.86 % at epoch 70\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.1554e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.64 % at epoch 71\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.0047e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.59 % at epoch 72\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.8822e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.65 % at epoch 73\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.9508e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.65 % at epoch 74\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7753e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.56 % at epoch 75\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7625e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.56 % at epoch 76\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.5236e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.41 % at epoch 77\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.4925e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.49 % at epoch 78\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.3826e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.41 % at epoch 79\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.4193e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.35 % at epoch 80\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0149 - accuracy: 0.9958\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  80.37 % at epoch 81\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.9742e-04 - accuracy: 0.9999\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.36 % at epoch 82\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.4638e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.31 % at epoch 83\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.3231e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.38 % at epoch 84\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2338e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.55 % at epoch 85\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1458e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.33 % at epoch 86\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.0679e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.32 % at epoch 87\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.0635e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.45 % at epoch 88\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.8300e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.41 % at epoch 89\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.5125e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.32 % at epoch 90\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 9.3197e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.37 % at epoch 91\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.9373e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.36 % at epoch 92\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.4972e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.3 % at epoch 93\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.0877e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.5 % at epoch 94\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.9460e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.54 % at epoch 95\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0081 - accuracy: 0.9976\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  81.55 % at epoch 96\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.0678e-04 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  81.84 % at epoch 97\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.5538e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  81.95 % at epoch 98\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.9108e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.14 % at epoch 99\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.4774e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.13 % at epoch 100\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.0173e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.21 % at epoch 101\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.7739e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.13 % at epoch 102\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.4032e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.23 % at epoch 103\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.1585e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.23 % at epoch 104\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.8146e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.23 % at epoch 105\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.8469e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.44 % at epoch 106\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.5110e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.46 % at epoch 107\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.2552e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.3 % at epoch 108\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.0004e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.54 % at epoch 109\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.2272e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.36 % at epoch 110\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.6783e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.28 % at epoch 111\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.3910e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.13 % at epoch 112\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.8601e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.44 % at epoch 113\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.8782e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.56 % at epoch 114\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.0423e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.67 % at epoch 115\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0042 - accuracy: 0.9985\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  81.32 % at epoch 116\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 4.5848e-04 - accuracy: 0.9997\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.18 % at epoch 117\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.7482e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.28 % at epoch 118\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.2283e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.19 % at epoch 119\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.9790e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.27 % at epoch 120\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.6572e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.43 % at epoch 121\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.4625e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.5 % at epoch 122\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.2332e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.41 % at epoch 123\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 4.0818e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.44 % at epoch 124\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.8469e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.42 % at epoch 125\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.6856e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.46 % at epoch 126\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.5603e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.5 % at epoch 127\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.3155e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.57 % at epoch 128\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.3319e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.54 % at epoch 129\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.0556e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.5 % at epoch 130\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.9860e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.4 % at epoch 131\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.7673e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.55 % at epoch 132\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.5886e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.68 % at epoch 133\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.8479e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.3 % at epoch 134\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.8383e-05 - accuracy: 1.0000\n",
            "acc_max =  82.86 % at epoch 70\n",
            "epoch_acc =  82.58 % at epoch 135\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.8227e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.91 % at epoch 136\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.2029e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.77 % at epoch 137\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0079 - accuracy: 0.9976\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.31 % at epoch 138\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.0529e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.71 % at epoch 139\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.2780e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.77 % at epoch 140\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.9698e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.79 % at epoch 141\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.7569e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.73 % at epoch 142\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.5858e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.76 % at epoch 143\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.3938e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.77 % at epoch 144\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.2696e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.8 % at epoch 145\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.1547e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.74 % at epoch 146\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.0447e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.72 % at epoch 147\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.9336e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.69 % at epoch 148\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.8683e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.63 % at epoch 149\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.8177e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.61 % at epoch 150\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7319e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.56 % at epoch 151\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7243e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.55 % at epoch 152\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.6431e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.31 % at epoch 153\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.6056e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.51 % at epoch 154\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 1.6421e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.56 % at epoch 155\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 1.5023e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.45 % at epoch 156\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.3742e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.45 % at epoch 157\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.3182e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.66 % at epoch 158\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2849e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.34 % at epoch 159\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2677e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.63 % at epoch 160\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7319e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.42 % at epoch 161\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1203e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.37 % at epoch 162\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.0294e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.64 % at epoch 163\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1200e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.57 % at epoch 164\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.1886e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.68 % at epoch 165\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.4254e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.69 % at epoch 166\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.3540e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.68 % at epoch 167\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0087 - accuracy: 0.9972\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  81.47 % at epoch 168\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.9543e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  81.72 % at epoch 169\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.1770e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  81.86 % at epoch 170\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.8837e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.0 % at epoch 171\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.6713e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.09 % at epoch 172\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.5166e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.18 % at epoch 173\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.3925e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.21 % at epoch 174\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2825e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.23 % at epoch 175\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1917e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.27 % at epoch 176\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1193e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.29 % at epoch 177\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.0496e-05 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.36 % at epoch 178\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.8088e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.36 % at epoch 179\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.2733e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.38 % at epoch 180\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.8163e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.41 % at epoch 181\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.2257e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.51 % at epoch 182\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.8131e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.49 % at epoch 183\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.4259e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.57 % at epoch 184\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.0572e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.55 % at epoch 185\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.6749e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.54 % at epoch 186\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.3011e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.6 % at epoch 187\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.0737e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.64 % at epoch 188\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.6665e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.6 % at epoch 189\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.4046e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.63 % at epoch 190\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 5.4795e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.59 % at epoch 191\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.9654e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.78 % at epoch 192\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.0778e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.47 % at epoch 193\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.7260e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.43 % at epoch 194\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 4.5900e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.32 % at epoch 195\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.4491e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.54 % at epoch 196\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.1912e-06 - accuracy: 1.0000\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.73 % at epoch 197\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  80.04 % at epoch 198\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "acc_max =  82.91 % at epoch 136\n",
            "epoch_acc =  82.71 % at epoch 199\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.8737e-04 - accuracy: 0.9999\n",
            "acc_max =  83.35 % at epoch 200\n",
            "epoch_acc =  83.35 % at epoch 200\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2404e-05 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.51 % at epoch 201\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.0447e-05 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.42 % at epoch 202\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.0534e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.4 % at epoch 203\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.9754e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.46 % at epoch 204\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.2833e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.36 % at epoch 205\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.6158e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.36 % at epoch 206\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.0651e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.27 % at epoch 207\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.6523e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.27 % at epoch 208\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.2316e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.22 % at epoch 209\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.9277e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.25 % at epoch 210\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.6377e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.23 % at epoch 211\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.4870e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.18 % at epoch 212\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.2732e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.09 % at epoch 213\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.1105e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.07 % at epoch 214\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.9407e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.04 % at epoch 215\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.8226e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.09 % at epoch 216\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.6867e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.0 % at epoch 217\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.5786e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.97 % at epoch 218\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.3665e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.94 % at epoch 219\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.3436e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.97 % at epoch 220\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.2294e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.0 % at epoch 221\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.0635e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.95 % at epoch 222\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.1050e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.92 % at epoch 223\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.7649e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.94 % at epoch 224\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.7186e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.94 % at epoch 225\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.6531e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  83.09 % at epoch 226\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.4686e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.47 % at epoch 227\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.4778e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.91 % at epoch 228\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.6157e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.98 % at epoch 229\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0056 - accuracy: 0.9984\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.18 % at epoch 230\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.5790e-05 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.66 % at epoch 231\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.6978e-05 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.77 % at epoch 232\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.3426e-05 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.84 % at epoch 233\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1860e-05 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.78 % at epoch 234\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.8127e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.83 % at epoch 235\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.6961e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.73 % at epoch 236\n",
            "354/354 [==============================] - 22s 61ms/step - loss: 7.6604e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.78 % at epoch 237\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.9560e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.76 % at epoch 238\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.1551e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.82 % at epoch 239\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 5.4178e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.78 % at epoch 240\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.9586e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.82 % at epoch 241\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.5475e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.84 % at epoch 242\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.1088e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.83 % at epoch 243\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.7342e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.82 % at epoch 244\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.4435e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.78 % at epoch 245\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 3.1578e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.77 % at epoch 246\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 2.9004e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.67 % at epoch 247\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.7168e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.78 % at epoch 248\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.6103e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.69 % at epoch 249\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.3572e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.83 % at epoch 250\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.2175e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.77 % at epoch 251\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.1167e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.73 % at epoch 252\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 2.0064e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.86 % at epoch 253\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.9123e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.78 % at epoch 254\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7905e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.73 % at epoch 255\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7284e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.8 % at epoch 256\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.6547e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.69 % at epoch 257\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.5880e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.76 % at epoch 258\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.5252e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.67 % at epoch 259\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.4219e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.8 % at epoch 260\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.3192e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.73 % at epoch 261\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2886e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.8 % at epoch 262\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2397e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.74 % at epoch 263\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2095e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.81 % at epoch 264\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1691e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.68 % at epoch 265\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1286e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.68 % at epoch 266\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.6242e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.73 % at epoch 267\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0061 - accuracy: 0.9977\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.22 % at epoch 268\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.7987e-04 - accuracy: 0.9999\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.38 % at epoch 269\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.0722e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.29 % at epoch 270\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.9214e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.28 % at epoch 271\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 2.4775e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.27 % at epoch 272\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.2482e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.19 % at epoch 273\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.1176e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.16 % at epoch 274\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.0297e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.16 % at epoch 275\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.9674e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.19 % at epoch 276\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.9085e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.22 % at epoch 277\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.8556e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.22 % at epoch 278\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7999e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.18 % at epoch 279\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7481e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.22 % at epoch 280\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.6877e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.25 % at epoch 281\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 1.6174e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.24 % at epoch 282\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 1.5707e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.32 % at epoch 283\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.5063e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.28 % at epoch 284\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.4578e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.3 % at epoch 285\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.3979e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.29 % at epoch 286\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.3325e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.37 % at epoch 287\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 1.2831e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.36 % at epoch 288\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2301e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.36 % at epoch 289\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1672e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.36 % at epoch 290\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1286e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.34 % at epoch 291\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.0697e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.38 % at epoch 292\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.0202e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.37 % at epoch 293\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.8295e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.41 % at epoch 294\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.2358e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.26 % at epoch 295\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.1064e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.45 % at epoch 296\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.3305e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.26 % at epoch 297\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.9237e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.32 % at epoch 298\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.7486e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.42 % at epoch 299\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.2054e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.55 % at epoch 300\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.9294e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.44 % at epoch 301\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.5185e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.41 % at epoch 302\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.4077e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.38 % at epoch 303\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.0419e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.58 % at epoch 304\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 5.7909e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.5 % at epoch 305\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 5.4791e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.48 % at epoch 306\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.4982e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.54 % at epoch 307\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.7448e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.66 % at epoch 308\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.0635e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.7 % at epoch 309\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 4.7286e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.75 % at epoch 310\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.5282e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.36 % at epoch 311\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 0.0062 - accuracy: 0.9984\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  81.67 % at epoch 312\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.3835e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  81.8 % at epoch 313\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 4.8102e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  81.86 % at epoch 314\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 3.5112e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.0 % at epoch 315\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.7984e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.08 % at epoch 316\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.3543e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.14 % at epoch 317\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 2.0322e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.18 % at epoch 318\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.7907e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.24 % at epoch 319\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.5992e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.29 % at epoch 320\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.4476e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.33 % at epoch 321\n",
            "354/354 [==============================] - 22s 63ms/step - loss: 1.3207e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.32 % at epoch 322\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.2117e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.36 % at epoch 323\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.1170e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.38 % at epoch 324\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 1.0412e-06 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.44 % at epoch 325\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.7033e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.45 % at epoch 326\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 9.1063e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.45 % at epoch 327\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.5645e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.43 % at epoch 328\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 8.1277e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.48 % at epoch 329\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.7284e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.49 % at epoch 330\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.3753e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.45 % at epoch 331\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 7.0037e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.5 % at epoch 332\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.7528e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.49 % at epoch 333\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.4401e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.52 % at epoch 334\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 6.2021e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.44 % at epoch 335\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.9779e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.49 % at epoch 336\n",
            "354/354 [==============================] - 22s 62ms/step - loss: 5.7665e-07 - accuracy: 1.0000\n",
            "acc_max =  83.51 % at epoch 201\n",
            "epoch_acc =  82.53 % at epoch 337\n",
            " 10/354 [..............................] - ETA: 21s - loss: 4.3361e-07 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-b330253960aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs_train_patches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mld_train_patches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mtrainacc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs_tt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mld_tt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict((hs_tt, ld_tt))\n",
        "\n",
        "n_samples = 12189\n",
        "correct = 0\n",
        "for i in tqdm.tqdm(range(n_samples)):\n",
        "  if np.argmax(preds[i]) == np.argmax(categorical_test_labels[i]):\n",
        "      correct = correct + 1\n",
        "accuracy = correct/n_samples\n",
        "\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5cuTEODKLwH",
        "outputId": "e39cae3c-041d-4fd9-80a6-cd2e4bf63ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12189/12189 [00:00<00:00, 261543.20it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8017064566412339"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5dWM35mPbTn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BER5Xen5oS52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AOZk4bYjoS8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rmLdQ61gtkIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Qdrs-JsnKXR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2zl2Y8DEtjvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l6nvhGYCKd3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **START FROM HERE**"
      ],
      "metadata": {
        "id": "R9UApu0uKhIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_co = np.genfromtxt('/content/drive/MyDrive/datasets/houston/trainingdata.txt')\n",
        "train_co.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvmBSrZ0tlW_",
        "outputId": "2a74b98f-3e38-4afc-f624-2f1a013e752c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2832, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_co = np.genfromtxt('/content/drive/MyDrive/datasets/houston/test.txt')\n",
        "test_co.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-cftGFPtmAS",
        "outputId": "066db1c5-4682-47ba-f7e9-73476afec1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12197, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = rasterio.open('/content/2013_DFTC/2013_IEEE_GRSS_DF_Contest_CASI.tif')\n",
        "ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJJtGyFpt15T",
        "outputId": "37285e61-cf7b-4790-c540-19f4f36a62c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rasterio._env:CPLE_AppDefined in /content/2013_DFTC/2013_IEEE_GRSS_DF_Contest_CASI.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(349, 1905)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "hysp=np.zeros((144,349,1905))\n",
        "for i in range(144):\n",
        "  x=ds.read(i+1)\n",
        "  m=np.amax(x)\n",
        "  x=x/m\n",
        "  hysp[i]=x\n",
        "print(hysp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoftMuYStjsj",
        "outputId": "4987d064-5a97-4978-93d0-31d1af06bfb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(144, 349, 1905)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hysp1=np.swapaxes(hysp,2,0)\n",
        "print(hysp1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErVQC9DNv6Pa",
        "outputId": "e8335911-0f75-472e-def4-fb533e01885a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1905, 349, 144)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hs_train = []\n",
        "train_label = []\n",
        "for i in train_co:\n",
        "  hs_train.append(hysp1[int(i[0]),int(i[1])])\n",
        "  train_label.append(i[2]-1)\n",
        "hs_train = np.asarray(hs_train)\n",
        "train_label = np.asarray(train_label)"
      ],
      "metadata": {
        "id": "YSuDQxRkv6IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hs_train.shape)\n",
        "hs_train = hs_train[:,:,np.newaxis]\n",
        "print(hs_train.shape)\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QghwnqDlv58Z",
        "outputId": "93dda46e-2f51-4219-d668-798baefdc95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2832, 144)\n",
            "(2832, 144, 1)\n",
            "(2832,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hs_test = []\n",
        "test_label = []\n",
        "for i in test_co:\n",
        "  hs_test.append(hysp1[int(i[0]),int(i[1])])\n",
        "  test_label.append(i[2]-1)\n",
        "hs_test = np.asarray(hs_test)\n",
        "test_label = np.asarray(test_label)"
      ],
      "metadata": {
        "id": "rvtd-9WCL3QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hs_test.shape)\n",
        "hs_test = hs_test[:,:,np.newaxis]\n",
        "print(hs_test.shape)\n",
        "print(test_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa1CUUKGMBgv",
        "outputId": "53a47a79-092b-479f-86db-0d75570111eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12197, 144)\n",
            "(12197, 144, 1)\n",
            "(12197,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds2=rasterio.open(\"/content/2013_DFTC/2013_IEEE_GRSS_DF_Contest_LiDAR.tif\")\n",
        "print(ds2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1McmKeqv50Q",
        "outputId": "c5563e79-49f0-413f-aca3-365f4f9bf024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(349, 1905)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=ds2.read(1)\n",
        "m=np.amax(x)\n",
        "x=x/m\n",
        "ll=np.swapaxes(x,0,1)\n",
        "print(ll.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sBGAZi6v5od",
        "outputId": "13f4f7a8-4b82-468a-9d04-580ff87d003b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1905, 349)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p=3\n",
        "ld_train=np.zeros((2832,p,p))\n",
        "for i in range(2832):\n",
        "  x=int(train_co[i][0])\n",
        "  y=int(train_co[i][1])\n",
        "  if y>=2 and y<=348 and x>=2 and x<=1904:\n",
        "      ld_train[i]=ll[ x-2:x+1 , y-2:y+1 ]\n",
        "  \n",
        "print(ld_train.shape)\n",
        "ld_train=np.reshape(ld_train,(2832,3,3,1))\n",
        "# print(ld_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLU1gGPYv5dt",
        "outputId": "81535113-66d2-437b-b215-f70795ac3484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2832, 3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hs_tr90 = np.empty([2832,11,11,144], dtype = 'float32')\n",
        "# hs_tr180 = np.empty([2832,11,11,144], dtype = 'float32')\n",
        "# hs_tr270 = np.empty([2832,11,11,144], dtype = 'float32')\n",
        "\n",
        "ld_tr90 = np.empty([2832,3,3,1], dtype = 'float32')\n",
        "ld_tr180 = np.empty([2832,3,3,1], dtype = 'float32')\n",
        "ld_tr270 = np.empty([2832,3,3,1], dtype = 'float32')\n",
        "\n",
        "for i in tqdm.tqdm(range(2832)):\n",
        "  # hs_tr90[i,:,:,:] = np.rot90(hs_tr[i,:,:,:])\n",
        "  # hs_tr180[i,:,:,:] = np.rot90(hs_tr90[i,:,:,:])\n",
        "  # hs_tr270[i,:,:,:] = np.rot90(hs_tr180[i,:,:,:])\n",
        "\n",
        "  ld_tr90[i,:,:,:] = np.rot90(ld_train[i,:,:,:])\n",
        "  ld_tr180[i,:,:,:] = np.rot90(ld_tr90[i,:,:,:])\n",
        "  ld_tr270[i,:,:,:] = np.rot90(ld_tr180[i,:,:,:])  \n",
        "\n",
        "hs_train_patches = np.concatenate([hs_train, hs_train, hs_train, hs_train], axis = 0)\n",
        "ld_train_patches = np.concatenate([ld_train, ld_tr90, ld_tr180, ld_tr270], axis = 0)\n",
        "train_labels = np.concatenate([train_label, train_label, train_label, train_label] , axis = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt2CkINZhDMU",
        "outputId": "5f20b9d4-a63a-40e7-97ae-b237db163b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2832/2832 [00:00<00:00, 16067.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hs_train_patches.shape)\n",
        "print(ld_train_patches.shape)\n",
        "ld_train_patches=np.reshape(ld_train_patches,(11328,9,1))\n",
        "print(ld_train_patches.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGK84Md0iAdk",
        "outputId": "3703412f-374a-4296-f0fb-737188d7f2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11328, 144, 1)\n",
            "(11328, 3, 3, 1)\n",
            "(11328, 9, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p=3\n",
        "ld_test=np.zeros((12197,p,p))\n",
        "for i in range(12197):\n",
        "  x=int(test_co[i][0])\n",
        "  y=int(test_co[i][1])\n",
        "  if y>=2 and y<=348 and x>=2 and x<=1904:\n",
        "      ld_test[i]=ll[ x-2:x+1 , y-2:y+1 ]\n",
        "  \n",
        "print(ld_test.shape)\n",
        "ld_test=np.reshape(ld_test,(12197,9,1))\n",
        "print(ld_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPGlvndzMION",
        "outputId": "6818f0c9-4e49-4ab9-b4a6-bf5e8dafe4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12197, 3, 3)\n",
            "(12197, 9, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEncoder(layers.Layer):\n",
        "    def __init__(self, modality_dim, projection_dim):\n",
        "        super(PositionEncoder, self).__init__()\n",
        "        self.modality_dim = modality_dim\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=modality_dim, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, images):\n",
        "        positions = tf.range(start=0, limit=self.modality_dim, delta=1)\n",
        "        encoded = self.projection(images) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "GL_qsqauO4ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim      \n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, input, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=input, value=input, key=input\n",
        "        )\n",
        "        # print(\"attention_output\",attention_output)\n",
        "        proj_input = self.layernorm_1(input + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)"
      ],
      "metadata": {
        "id": "40obqRPaZESJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "projection_dim = 16\n",
        "embed_dim = 16\n",
        "dense_dim = 256\n",
        "num_heads = 8\n",
        "\n",
        "hyp_dim = 144\n",
        "ld_dim = 9\n",
        "\n",
        "hs_inp = keras.Input(shape=(144,1))\n",
        "ld_inp = keras.Input(shape=(9,1))\n",
        "\n",
        "hs_encoded = PositionEncoder(hyp_dim, projection_dim)(hs_inp)\n",
        "ld_encoded = PositionEncoder(ld_dim, projection_dim)(ld_inp)\n",
        "\n",
        "encoded = layers.Concatenate(axis=1)([hs_encoded,ld_encoded])\n",
        "\n",
        "encoder1 = TransformerEncoder(embed_dim, dense_dim, num_heads)(encoded)\n",
        "encoder2 = TransformerEncoder(embed_dim, dense_dim, num_heads)(encoder1)\n",
        "# encoder = TransformerEncoder(embed_dim, dense_dim, num_heads)(encoder)\n",
        "\n",
        "flatten = layers.Flatten()(encoder2)\n",
        "mid = layers.Reshape((-1,1))(layers.Dense(144, activation=\"sigmoid\")(flatten))\n",
        "output = layers.Dense(15, activation=\"softmax\")(layers.Flatten()(encoder1))\n",
        "\n",
        "model = keras.Model((hs_inp,ld_inp), (output,mid))"
      ],
      "metadata": {
        "id": "BUEHz-h3M8OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jejw5k-WXdyO",
        "outputId": "2420e0bb-e308-435b-aa37-623e2dd40706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_37 (InputLayer)          [(None, 144, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " input_38 (InputLayer)          [(None, 9, 1)]       0           []                               \n",
            "                                                                                                  \n",
            " position_encoder_31 (PositionE  (None, 144, 16)     2336        ['input_37[0][0]']               \n",
            " ncoder)                                                                                          \n",
            "                                                                                                  \n",
            " position_encoder_32 (PositionE  (None, 9, 16)       176         ['input_38[0][0]']               \n",
            " ncoder)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 153, 16)      0           ['position_encoder_31[0][0]',    \n",
            "                                                                  'position_encoder_32[0][0]']    \n",
            "                                                                                                  \n",
            " transformer_encoder_24 (Transf  (None, 153, 16)     17120       ['concatenate_14[0][0]']         \n",
            " ormerEncoder)                                                                                    \n",
            "                                                                                                  \n",
            " transformer_encoder_25 (Transf  (None, 153, 16)     17120       ['transformer_encoder_24[0][0]'] \n",
            " ormerEncoder)                                                                                    \n",
            "                                                                                                  \n",
            " flatten_9 (Flatten)            (None, 2448)         0           ['transformer_encoder_25[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_10 (Flatten)           (None, 2448)         0           ['transformer_encoder_24[0][0]'] \n",
            "                                                                                                  \n",
            " dense_97 (Dense)               (None, 144)          352656      ['flatten_9[0][0]']              \n",
            "                                                                                                  \n",
            " dense_98 (Dense)               (None, 15)           36735       ['flatten_10[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 144, 1)       0           ['dense_97[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 426,143\n",
            "Trainable params: 426,143\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_train_label = tf.keras.utils.to_categorical(train_label, num_classes=15, dtype=\"float32\")"
      ],
      "metadata": {
        "id": "ADOBfR-oaFLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_test_label = tf.keras.utils.to_categorical(test_label, num_classes=15, dtype=\"float32\")"
      ],
      "metadata": {
        "id": "LFbxRcMNaFLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_train_label = tf.keras.utils.to_categorical(train_labels, num_classes=15, dtype=\"float32\")\n",
        "categorical_train_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOtXTrbJlxV0",
        "outputId": "7ce2f4ba-bb78-4d36-8105-7f29d556ee60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11328, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(categorical_train_label.shape)\n",
        "print(categorical_test_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df0211b-a016-4857-bd49-a97f27f2c9e9",
        "id": "fG8M3nV1aFLH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2832, 15)\n",
            "(12197, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZbPgMEyjaFLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss= ['categorical_crossentropy','mse'] , optimizer= tf.keras.optimizers.Adam(learning_rate=5e-5) , metrics=[ 'accuracy' ])"
      ],
      "metadata": {
        "id": "qlI73w3AaFLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask(percent,hs1,ld1):\n",
        "  hs=hs1.copy()\n",
        "  ld=ld1.copy()\n",
        "\n",
        "  mask_hs = np.ones((hs.shape))\n",
        "  mask_ld = np.ones((ld.shape))\n",
        "\n",
        "  mask_hs=np.reshape(mask_hs,(-1))\n",
        "  id=np.arange(len(mask_hs))\n",
        "  np.random.shuffle(id)\n",
        "  id=id[:int(percent*len(id))]\n",
        "  # print(len(id))\n",
        "  mask_hs[id]=0\n",
        "  mask_hs=np.reshape(mask_hs,hs.shape)\n",
        "\n",
        "  mask_ld=np.reshape(mask_ld,(-1))\n",
        "  id=np.arange(len(mask_ld))\n",
        "  np.random.shuffle(id)\n",
        "  id=id[:int(percent*len(id))]\n",
        "  # print(len(id))\n",
        "  mask_ld[id]=0\n",
        "  mask_ld=np.reshape(mask_ld,ld.shape)\n",
        "\n",
        "  hs=hs*mask_hs\n",
        "  ld=ld*mask_ld\n",
        "\n",
        "  return hs,ld"
      ],
      "metadata": {
        "id": "yEiMTEfwiU-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochaccuracy = []\n",
        "highestaccuracy = [0]\n",
        "trainacc = []"
      ],
      "metadata": {
        "id": "_YppGijlaFLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_acc = highestaccuracy[-1]\n",
        "ep = 0\n",
        "predsf = np.zeros((12917, 15))\n",
        "epochs = 20\n",
        "for i in range(epochs):\n",
        "  gc.collect()\n",
        "  id1 = np.arange(len(hs_train_patches))\n",
        "  np.random.shuffle(id1)\n",
        "  id1 = id1[:]\n",
        "  hs1 = hs_train_patches[id1]\n",
        "  ld1 = ld_train_patches[id1]\n",
        "  h,l = mask(0.75, hs1, ld1)\n",
        "  y = categorical_train_label[id1]\n",
        "  \n",
        "  history = model.fit((h, l), (y,hs1), batch_size = 32, epochs=1)\n",
        "  trainacc.append(history.history[\"dense_98_accuracy\"])\n",
        "  preds = model.predict((hs_test, ld_test))[0]\n",
        "  conf = confusion_matrix(test_label, np.argmax(preds,1)) \n",
        "  acc = np.trace(conf)/np.sum(conf)\n",
        "  if acc>temp_acc:\n",
        "    temp_acc = acc\n",
        "    ep = i\n",
        "    predsf = preds\n",
        "  print('acc_max = ', np.round(100*temp_acc,2), '% at epoch', ep)\n",
        "  highestaccuracy.append(temp_acc)\n",
        "  print('epoch_acc = ', round(100*acc,2), '% at epoch', i)\n",
        "  epochaccuracy.append(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d78c1bb-7c6c-4d0e-b67f-8c924ecc0279",
        "id": "UeopUr-KaFLJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354/354 [==============================] - 7s 13ms/step - loss: 0.2275 - dense_98_loss: 0.2275 - reshape_3_loss: 2.8588e-05 - dense_98_accuracy: 0.9167 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  76.32 % at epoch 0\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.2044 - dense_98_loss: 0.2044 - reshape_3_loss: 2.4254e-05 - dense_98_accuracy: 0.9293 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  76.03 % at epoch 1\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1974 - dense_98_loss: 0.1973 - reshape_3_loss: 2.3674e-05 - dense_98_accuracy: 0.9334 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.51 % at epoch 2\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1964 - dense_98_loss: 0.1964 - reshape_3_loss: 2.2981e-05 - dense_98_accuracy: 0.9323 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.41 % at epoch 3\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1912 - dense_98_loss: 0.1912 - reshape_3_loss: 2.3019e-05 - dense_98_accuracy: 0.9318 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.04 % at epoch 4\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1972 - dense_98_loss: 0.1971 - reshape_3_loss: 2.2299e-05 - dense_98_accuracy: 0.9330 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.49 % at epoch 5\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1799 - dense_98_loss: 0.1798 - reshape_3_loss: 2.2003e-05 - dense_98_accuracy: 0.9364 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.67 % at epoch 6\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1879 - dense_98_loss: 0.1879 - reshape_3_loss: 2.1670e-05 - dense_98_accuracy: 0.9345 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.44 % at epoch 7\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1793 - dense_98_loss: 0.1792 - reshape_3_loss: 2.1430e-05 - dense_98_accuracy: 0.9369 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.22 % at epoch 8\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1788 - dense_98_loss: 0.1788 - reshape_3_loss: 2.1259e-05 - dense_98_accuracy: 0.9373 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.54 % at epoch 9\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1810 - dense_98_loss: 0.1810 - reshape_3_loss: 2.1689e-05 - dense_98_accuracy: 0.9365 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  74.6 % at epoch 10\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1772 - dense_98_loss: 0.1772 - reshape_3_loss: 2.1460e-05 - dense_98_accuracy: 0.9370 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.04 % at epoch 11\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1732 - dense_98_loss: 0.1732 - reshape_3_loss: 2.1042e-05 - dense_98_accuracy: 0.9408 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.32 % at epoch 12\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1710 - dense_98_loss: 0.1710 - reshape_3_loss: 2.1426e-05 - dense_98_accuracy: 0.9375 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.79 % at epoch 13\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1684 - dense_98_loss: 0.1683 - reshape_3_loss: 2.0670e-05 - dense_98_accuracy: 0.9389 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.43 % at epoch 14\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1617 - dense_98_loss: 0.1616 - reshape_3_loss: 2.1282e-05 - dense_98_accuracy: 0.9450 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.05 % at epoch 15\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1761 - dense_98_loss: 0.1760 - reshape_3_loss: 2.0886e-05 - dense_98_accuracy: 0.9358 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.36 % at epoch 16\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1682 - dense_98_loss: 0.1682 - reshape_3_loss: 2.0571e-05 - dense_98_accuracy: 0.9417 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.22 % at epoch 17\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1714 - dense_98_loss: 0.1713 - reshape_3_loss: 2.0564e-05 - dense_98_accuracy: 0.9410 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  74.77 % at epoch 18\n",
            "354/354 [==============================] - 5s 13ms/step - loss: 0.1725 - dense_98_loss: 0.1725 - reshape_3_loss: 2.0324e-05 - dense_98_accuracy: 0.9395 - reshape_3_accuracy: 9.8085e-06\n",
            "acc_max =  76.32 % at epoch 0\n",
            "epoch_acc =  75.14 % at epoch 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict((hs_test, ld_test))\n",
        "\n",
        "n_samples = 12189\n",
        "correct = 0\n",
        "for i in tqdm.tqdm(range(n_samples)):\n",
        "  if np.argmax(preds[i]) == np.argmax(categorical_test_label[i]):\n",
        "      correct = correct + 1\n",
        "accuracy = correct/n_samples\n",
        "\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "yEdqNSUHcDZe",
        "outputId": "a5185aa4-1f49-4373-f9b9-20cb497a39ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/12189 [00:00<00:13, 920.41it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-173-012a58ca5d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_test_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lLMGyaotda5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}